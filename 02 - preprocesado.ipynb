{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs97tNbzINjahompzHH6UW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johansbustamante-gif/Proyecto-Inteligencia-Artificial/blob/main/02%20-%20preprocesado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s_RMPLXtopaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c091c83f-2929-47b3-e1c6-0c128cbccb70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Montando Google Drive...\n",
            "Mounted at /content/drive\n",
            "✅ Drive montado.\n",
            "\n",
            "📂 Leyendo archivo: /content/drive/MyDrive/DataProyectoIA/train.csv\n",
            "   → Shape inicial: (692500, 21)\n",
            "✅ No se eliminaron columnas por NaN excesivo.\n",
            "🧩 Duplicados eliminados: 0\n",
            "🚮 Eliminando 1639 filas con >50% NaN\n",
            "🔢 Numéricas: 6 | Categóricas: 15\n",
            "  • Cat 'E_VALORMATRICULAUNIVERSIDAD': 4648 NaN → 'Entre 1 millón y menos de 2.5 millones'\n",
            "  • Cat 'E_HORASSEMANATRABAJA': 29218 NaN → 'Más de 30 horas'\n",
            "  • Cat 'F_ESTRATOVIVIENDA': 30498 NaN → 'Estrato 2'\n",
            "  • Cat 'F_TIENEINTERNET': 24990 NaN → 'Si'\n",
            "  • Cat 'F_EDUCACIONPADRE': 21539 NaN → 'Secundaria (Bachillerato) completa'\n",
            "  • Cat 'F_TIENELAVADORA': 38134 NaN → 'Si'\n",
            "  • Cat 'F_TIENEAUTOMOVIL': 41984 NaN → 'No'\n",
            "  • Cat 'E_PAGOMATRICULAPROPIO': 4859 NaN → 'No'\n",
            "  • Cat 'F_TIENECOMPUTADOR': 36464 NaN → 'Si'\n",
            "  • Cat 'F_TIENEINTERNET.1': 24990 NaN → 'Si'\n",
            "  • Cat 'F_EDUCACIONMADRE': 22025 NaN → 'Secundaria (Bachillerato) completa'\n",
            "⚖️ Tratando outliers por IQR (eliminando filas con outlier en cualquier columna numérica).\n",
            "  • INDICADOR_1: 69484 outliers fuera de [0.039, 0.479]\n",
            "  • INDICADOR_2: 32523 outliers fuera de [0.066, 0.455]\n",
            "  • INDICADOR_3: 35782 outliers fuera de [0.198, 0.350]\n",
            "  • INDICADOR_4: 73256 outliers fuera de [0.186, 0.373]\n",
            "🗑️ Filas eliminadas por outliers: 87380\n",
            "✅ Shape final: (603481, 21)\n",
            "💾 Guardando resultado en: /content/drive/MyDrive/DataProyectoIA/train_limpio.csv\n",
            "🎯 Limpieza finalizada.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 🧹 Limpieza y procesado sencillo en Colab\n",
        "# (con detección segura de formatos de fecha)\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from scipy import stats\n",
        "from google.colab import drive\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Montar Google Drive\n",
        "print(\"🔗 Montando Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"✅ Drive montado.\\n\")\n",
        "\n",
        "# Rutas (ajusta si hace falta)\n",
        "input_path = '/content/drive/MyDrive/DataProyectoIA/train.csv'\n",
        "output_path = '/content/drive/MyDrive/DataProyectoIA/train_limpio.csv'\n",
        "\n",
        "# Función auxiliar: intentar varios formatos comunes sin warnings\n",
        "def try_parse_date_series(s: pd.Series, min_parsed_frac=0.5):\n",
        "    \"\"\"\n",
        "    Intenta parsear la Series `s` usando formatos comunes; devuelve parsed Series\n",
        "    si alguno parsea >= min_parsed_frac, sino devuelve None.\n",
        "    \"\"\"\n",
        "    if s.dropna().empty:\n",
        "        return None\n",
        "\n",
        "    formats = [\n",
        "        \"%Y-%m-%d\", \"%d/%m/%Y\", \"%m/%d/%Y\", \"%Y/%m/%d\",\n",
        "        \"%d-%m-%Y\", \"%Y.%m.%d\", \"%d %b %Y\", \"%d %B %Y\",\n",
        "        \"%Y%m%d\", \"%d%m%Y\"\n",
        "    ]\n",
        "    sample = s.dropna().astype(str)\n",
        "    # pruebo formatos explícitos (evita warnings de infer)\n",
        "    for fmt in formats:\n",
        "        parsed = pd.to_datetime(sample, format=fmt, errors='coerce')\n",
        "        frac = parsed.notna().mean()\n",
        "        if frac >= min_parsed_frac:\n",
        "            # reconstruyo con mismos índices que s (incluye NaN)\n",
        "            full_parsed = pd.to_datetime(s.astype(str), format=fmt, errors='coerce')\n",
        "            return full_parsed\n",
        "    # si ningún formato fijo funcionó, no forzamos parseo (evitamos dateutil/warnings)\n",
        "    return None\n",
        "\n",
        "# Función principal de limpieza\n",
        "def simple_clean_process_safe_dates(input_path,\n",
        "                                    output_path=None,\n",
        "                                    drop_col_threshold=0.9,\n",
        "                                    row_na_thresh=0.5,\n",
        "                                    outlier_method='iqr',\n",
        "                                    iqr_multiplier=1.5,\n",
        "                                    fill_categorical_with_mode=True,\n",
        "                                    fill_unknown_label=\"__DESCONOCIDO__\",\n",
        "                                    date_min_parsed_frac=0.5,\n",
        "                                    verbose=True):\n",
        "    if verbose: print(f\"📂 Leyendo archivo: {input_path}\")\n",
        "    df = pd.read_csv(input_path)\n",
        "    if verbose: print(f\"   → Shape inicial: {df.shape}\")\n",
        "\n",
        "    # 1) Eliminar columnas con muchos NaN\n",
        "    col_nan_ratio = df.isna().mean()\n",
        "    cols_to_drop = col_nan_ratio[col_nan_ratio > drop_col_threshold].index.tolist()\n",
        "    if cols_to_drop:\n",
        "        if verbose: print(f\"🧹 Eliminando {len(cols_to_drop)} columnas con >{drop_col_threshold*100:.0f}% NaN\")\n",
        "        df = df.drop(columns=cols_to_drop)\n",
        "    else:\n",
        "        if verbose: print(\"✅ No se eliminaron columnas por NaN excesivo.\")\n",
        "\n",
        "    # 2) Duplicados\n",
        "    before = len(df)\n",
        "    df = df.drop_duplicates()\n",
        "    if verbose: print(f\"🧩 Duplicados eliminados: {before - len(df)}\")\n",
        "\n",
        "    # 3) Eliminar filas con muchos NaN\n",
        "    row_nan_ratio = df.isna().mean(axis=1)\n",
        "    rows_to_drop = row_nan_ratio[row_nan_ratio > row_na_thresh].index\n",
        "    if len(rows_to_drop) > 0:\n",
        "        if verbose: print(f\"🚮 Eliminando {len(rows_to_drop)} filas con >{row_na_thresh*100:.0f}% NaN\")\n",
        "        df = df.drop(index=rows_to_drop)\n",
        "    else:\n",
        "        if verbose: print(\"✅ No se eliminaron filas por NaN excesivo.\")\n",
        "\n",
        "    # 4) Intentar parsear fechas de manera segura (sin warnings)\n",
        "    obj_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "    for c in obj_cols[:]:\n",
        "        try:\n",
        "            parsed = try_parse_date_series(df[c], min_parsed_frac=date_min_parsed_frac)\n",
        "            if parsed is not None:\n",
        "                if verbose: print(f\"📅 Columna '{c}' convertida a datetime (>= {date_min_parsed_frac*100:.0f}% parseada).\")\n",
        "                df[c] = parsed\n",
        "        except Exception:\n",
        "            # si algo falla, simplemente no convertimos esa columna\n",
        "            pass\n",
        "\n",
        "    # 5) Separar tipos y mostrar\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
        "    if verbose: print(f\"🔢 Numéricas: {len(num_cols)} | Categóricas: {len(cat_cols)}\")\n",
        "\n",
        "    # 6) Imputación\n",
        "    for c in num_cols:\n",
        "        miss = df[c].isna().sum()\n",
        "        if miss:\n",
        "            med = df[c].median()\n",
        "            df[c] = df[c].fillna(med)\n",
        "            if verbose: print(f\"  • Num '{c}': {miss} NaN → mediana={med}\")\n",
        "\n",
        "    for c in cat_cols:\n",
        "        miss = df[c].isna().sum()\n",
        "        if miss:\n",
        "            if fill_categorical_with_mode:\n",
        "                try:\n",
        "                    mode = df[c].mode(dropna=True).iloc[0]\n",
        "                except Exception:\n",
        "                    mode = fill_unknown_label\n",
        "            else:\n",
        "                mode = fill_unknown_label\n",
        "            df[c] = df[c].fillna(mode)\n",
        "            if verbose: print(f\"  • Cat '{c}': {miss} NaN → '{mode}'\")\n",
        "\n",
        "    # 7) Outliers por IQR (elimina filas con outlier en cualquier num_col)\n",
        "    if outlier_method == 'iqr' and num_cols:\n",
        "        if verbose: print(\"⚖️ Tratando outliers por IQR (eliminando filas con outlier en cualquier columna numérica).\")\n",
        "        to_drop = set()\n",
        "        for c in num_cols:\n",
        "            q1, q3 = df[c].quantile([0.25, 0.75])\n",
        "            iqr = q3 - q1\n",
        "            low, high = q1 - iqr_multiplier * iqr, q3 + iqr_multiplier * iqr\n",
        "            mask = (df[c] < low) | (df[c] > high)\n",
        "            if mask.any():\n",
        "                if verbose: print(f\"  • {c}: {mask.sum()} outliers fuera de [{low:.3f}, {high:.3f}]\")\n",
        "                to_drop.update(df[mask].index.tolist())\n",
        "        if to_drop:\n",
        "            df = df.drop(index=list(to_drop))\n",
        "            if verbose: print(f\"🗑️ Filas eliminadas por outliers: {len(to_drop)}\")\n",
        "        else:\n",
        "            if verbose: print(\"✅ No se detectaron outliers por IQR.\")\n",
        "    else:\n",
        "        if verbose: print(\"⚠️ No se aplica tratamiento de outliers o no hay columnas numéricas.\")\n",
        "\n",
        "    df = df.reset_index(drop=True)\n",
        "    if verbose:\n",
        "        print(f\"✅ Shape final: {df.shape}\")\n",
        "        print(f\"💾 Guardando resultado en: {output_path}\")\n",
        "\n",
        "    if output_path:\n",
        "        df.to_csv(output_path, index=False)\n",
        "\n",
        "    print(\"🎯 Limpieza finalizada.\")\n",
        "    return df\n",
        "\n",
        "# Ejecutar limpieza\n",
        "df_clean = simple_clean_process_safe_dates(\n",
        "    input_path=input_path,\n",
        "    output_path=output_path,\n",
        "    drop_col_threshold=0.9,\n",
        "    row_na_thresh=0.5,\n",
        "    outlier_method='iqr',\n",
        "    iqr_multiplier=1.5,\n",
        "    fill_categorical_with_mode=True,\n",
        "    date_min_parsed_frac=0.5,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}